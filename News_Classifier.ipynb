{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76d45d03-5308-4c00-bdff-7ff3ce3384da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample Dataset ---\n",
      "                                                text  label\n",
      "0  Wall St. Bears Claw Back Into the Black (Reute...      2\n",
      "1  Carlyle Looks Toward Commercial Aerospace (Reu...      2\n",
      "2  Oil and Economy Cloud Stocks' Outlook (Reuters...      2\n",
      "3  Iraq Halts Oil Exports from Main Southern Pipe...      2\n",
      "4  Oil prices soar to all-time record, posing new...      2\n",
      "\n",
      "\n",
      "--- Preprocessed Text ---\n",
      "                                                text  label\n",
      "0  wall st bears claw back into the black reuters...      2\n",
      "1  carlyle looks toward commercial aerospace reut...      2\n",
      "2  oil and economy cloud stocks outlook reuters r...      2\n",
      "3  iraq halts oil exports from main southern pipe...      2\n",
      "4  oil prices soar to alltime record posing new m...      2\n",
      "\n",
      "\n",
      "Shape of training data matrix: (96000, 1000)\n",
      "Shape of testing data matrix: (24000, 1000)\n",
      "\n",
      "\n",
      "--- Model Training Complete ---\n",
      "\n",
      "\n",
      "--- Model Evaluation ---\n",
      "Accuracy: 0.85\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      6000\n",
      "           1       0.90      0.94      0.92      6000\n",
      "           2       0.83      0.81      0.82      6000\n",
      "           3       0.83      0.80      0.81      6000\n",
      "\n",
      "    accuracy                           0.85     24000\n",
      "   macro avg       0.85      0.85      0.85     24000\n",
      "weighted avg       0.85      0.85      0.85     24000\n",
      "\n",
      "--- Predictions on New Headlines ---\n",
      "Headline: 'The S&P 500 futures rise on tech stock gains' -> Predicted Label: Business\n",
      "Headline: 'Olympic champion breaks world record in swimming' -> Predicted Label: Sports\n",
      "Headline: 'Researchers study the effects of a new medical treatment' -> Predicted Label: Tech/Sci-fi\n",
      "Headline: 'Breakthrough in renewable energy research drives global stock market surge' -> Predicted Label: Business\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import re\n",
    "import pickle as p\n",
    "\n",
    "# --- Step 1: Data Loading and Preparation ---\n",
    "\n",
    "# If your data is in a CSV file, uncomment the line below and replace 'your_dataset.csv'\n",
    "df = pd.read_csv(r'training_data.csv')\n",
    "\n",
    "print(\"--- Sample Dataset ---\")\n",
    "print(df.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Step 2: Text Preprocessing ---\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the text by converting to lowercase and removing punctuation.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "print(\"--- Preprocessed Text ---\")\n",
    "print(df.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Step 3: Feature Extraction ---\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "# TF-IDF stands for Term Frequency-Inverse Document Frequency. It converts text\n",
    "# into a matrix of numerical features. It gives more weight to words that are\n",
    "# unique to a document and less to common words like \"the\" or \"a\".\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the *same* vectorizer\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"Shape of training data matrix: {X_train_vec.shape}\")\n",
    "print(f\"Shape of testing data matrix: {X_test_vec.shape}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Step 4: Model Training ---\n",
    "\n",
    "# We'll use a Multinomial Naive Bayes classifier, which is a good baseline\n",
    "# for text classification tasks.\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "print(\"--- Model Training Complete ---\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Step 5: Model Evaluation ---\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "print(\"--- Model Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# --- Step 6: Prediction on New Data ---\n",
    "\n",
    "def predict_headline(headline_text):\n",
    "    \"\"\"\n",
    "    Takes a new headline, preprocesses it, and predicts its label.\n",
    "    \"\"\"\n",
    "    # Preprocess the new text\n",
    "    cleaned_text = preprocess_text(headline_text)\n",
    "    \n",
    "    # Vectorize the cleaned text\n",
    "    # We use .transform() here, NOT .fit_transform()\n",
    "    new_text_vec = vectorizer.transform([cleaned_text])\n",
    "    \n",
    "    # Make a prediction\n",
    "    prediction = model.predict(new_text_vec)\n",
    "\n",
    "    if prediction[0] == 0:\n",
    "        return 'World'\n",
    "    elif prediction[0] == 1:\n",
    "        return 'Sports'\n",
    "    elif prediction[0] == 2:\n",
    "        return 'Business'\n",
    "    else:\n",
    "        return 'Tech/Sci-fi'\n",
    "\n",
    "# --- Step 7: Test Cases---\n",
    "print(\"--- Predictions on New Headlines ---\")\n",
    "\n",
    "new_headline_1 = \"The S&P 500 futures rise on tech stock gains\"\n",
    "print(f\"Headline: '{new_headline_1}' -> Predicted Label: {predict_headline(new_headline_1)}\")\n",
    "\n",
    "new_headline_2 = \"Olympic champion breaks world record in swimming\"\n",
    "print(f\"Headline: '{new_headline_2}' -> Predicted Label: {predict_headline(new_headline_2)}\")\n",
    "\n",
    "new_headline_3 = \"Researchers study the effects of a new medical treatment\"\n",
    "print(f\"Headline: '{new_headline_3}' -> Predicted Label: {predict_headline(new_headline_3)}\")\n",
    "\n",
    "# --- Tricky Test Case ---\n",
    "tricky_headline = \"Breakthrough in renewable energy research drives global stock market surge\"\n",
    "print(f\"Headline: '{tricky_headline}' -> Predicted Label: {predict_headline(tricky_headline)}\")\n",
    "\n",
    "with open('news-model.pkl','wb') as f:\n",
    "    p.dump(model,f)\n",
    "\n",
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    p.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2dd80c-ab34-436d-8ce3-58c219850e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
